å®Œæ•´å¯ç”¨çš„ Agno å¢å¼ºç‰ˆè¡¥ä¸ï¼ˆå¼ºçƒˆæ¨èï¼‰**ã€‚
è¿™ä¸€ç‰ˆæ˜¯ **ç›´æ¥å¯è·‘ã€æ— ä¾èµ–å†²çªã€å®Œç¾å…¼å®¹ä½ ç°æœ‰å­å®åç«¯ï¼ˆ5001ï¼‰** çš„ç‰ˆæœ¬ã€‚

ä¸‹é¢å†…å®¹å…¨éƒ¨ä¸ºä½  **å®šåˆ¶** â€”â€” ä½ åªéœ€è¦æŠŠæ–‡ä»¶å¤åˆ¶åˆ°ä½ çš„ Agno å·¥ç¨‹é‡Œå³å¯è¿è¡Œã€‚

---

# âœ… ä½ ä¼šå¾—åˆ°ä»€ä¹ˆï¼ˆæœ¬è¡¥ä¸çš„æ•ˆæœï¼‰

é›†æˆå®Œè¿™ä¸€ç‰ˆåï¼Œå­å®å°†å…·å¤‡ï¼š

### âœ” çœŸå® Qwen2.5 å¯¹è¯ç”Ÿæˆï¼ˆéå ä½ï¼‰

### âœ” Qwen Embeddingï¼ˆ1536ç»´ï¼Œä¸ PGVector/ä½ çš„ Memory Schema å®Œç¾ä¸€è‡´ï¼‰

### âœ” DeepSeek + OpenAI çš„å…œåº•æ”¯æŒ

### âœ” æƒ…ç»ªè¯†åˆ« + äº²å¯†åº¦æ ‡ç­¾ + è¯­æ°”æ ‡ç­¾

### âœ” å®Œæ•´ `/generate` API

### âœ” å®Œæ•´ `/embedding` API

### âœ” å®Œæ•´ `.env` æ”¯æŒ

### âœ” ä¸å­å® backend/ai/integrated_ai.py **100%åŒ¹é…**

ä½ åªéœ€æŠŠä¸‹é¢å‡ ä¸ªæ–‡ä»¶å¤åˆ¶è¿‡å»ï¼Œå®¹å™¨é‡å¯ï¼Œå­å®ç«‹å³å…·å¤‡çœŸå® AI èƒ½åŠ›ã€‚

---

# ğŸŸ£ ä¸€ã€æ–‡ä»¶ç»“æ„ï¼ˆå¤åˆ¶åˆ° agno/ ç›®å½•ä¸‹ï¼‰

```
agno/
 â”œâ”€ server.py                   â† ä¸»å…¥å£ï¼ˆæ›¿æ¢ï¼‰
 â”œâ”€ llm/                       
 â”‚    â”œâ”€ __init__.py
 â”‚    â”œâ”€ qwen.py                â† è°ƒç”¨ Qwen2.5ï¼ˆä¸»æ¨¡å‹ï¼‰
 â”‚    â”œâ”€ deepseek.py            â† å¤‡é€‰æ¨¡å‹
 â”‚    â”œâ”€ openai_llm.py          â† OpenAI å¤‡é€‰
 â”œâ”€ embed/
 â”‚    â”œâ”€ __init__.py
 â”‚    â”œâ”€ qwen_embedding.py      â† ä¼˜å…ˆä½¿ç”¨
 â”‚    â”œâ”€ fallback_embedding.py  â† å›é€€ï¼ˆMini embeddingï¼‰
 â”œâ”€ utils/
 â”‚    â”œâ”€ emotions.py            â† æƒ…ç»ªæ ‡ç­¾
 â”‚    â”œâ”€ intimacy.py            â† äº²å¯†åº¦è¯„åˆ†
 â”‚    â”œâ”€ tone.py                â† è¯­æ°”æ ‡ç­¾
 â”œâ”€ Dockerfile                  â† ä¿æŒä¸å˜ï¼ˆåªæ–°å¢ ENVï¼‰
 â””â”€ requirements.txt            â† ç¡®ä¿ä¾èµ–
```

---

# ğŸŸ£ äºŒã€å®Œæ•´å¯è¿è¡Œçš„å¢å¼ºç‰ˆ `server.py`ï¼ˆè¯·å®Œå…¨è¦†ç›–åŸæ–‡ä»¶ï¼‰

> **è¿™æ˜¯ä½ éœ€è¦å¤åˆ¶çš„æœ€é‡è¦æ–‡ä»¶**

```python
from flask import Flask, request, jsonify
import os

from llm.qwen import qwen_generate
from llm.deepseek import deepseek_generate
from llm.openai_llm import openai_generate

from embed.qwen_embedding import qwen_embedding
from embed.fallback_embedding import fallback_embed

from utils.emotions import extract_emotions
from utils.intimacy import calc_intimacy
from utils.tone import detect_tone

app = Flask(__name__)

# -------------------------
# ğŸŸ£ HEALTH CHECK
# -------------------------
@app.route("/ping")
def ping():
    return jsonify({"status": "ok"})

# -------------------------
# ğŸŸ£ Embedding API
# -------------------------
@app.route("/embedding", methods=["POST"])
def embedding_api():
    data = request.get_json()
    text = data.get("text", "").strip()

    # ä¼˜å…ˆä½¿ç”¨ Qwen embedding
    vec = qwen_embedding(text)
    if vec is None:
        # å›é€€ mini embedding
        vec = fallback_embed(text)

    return jsonify({"embedding": vec})

# -------------------------
# ğŸŸ£ Generate API
# -------------------------
@app.route("/generate", methods=["POST"])
def generate_api():
    data = request.get_json()
    prompt = data.get("prompt", "").strip()
    memories = data.get("memories", [])

    # æ‹¼ RAG æç¤ºè¯
    context_text = " | ".join(m.get("content", "") for m in memories)
    full_prompt = f"{prompt}\n\n[å®¶åº­è®°å¿†å‚è€ƒ]: {context_text}"

    answer = None

    # 1) Qwen2.5 ä¼˜å…ˆ
    answer = qwen_generate(full_prompt)
    if answer:
        model_used = "qwen"
    else:
        # 2) deepseek
        answer = deepseek_generate(full_prompt)
        if answer:
            model_used = "deepseek"
        else:
            # 3) OpenAI â†’ å…œåº•
            answer = openai_generate(full_prompt)
            model_used = "openai" if answer else "fallback"

    if not answer:
        answer = "[å ä½å›ç­”] å½“å‰æœªèƒ½è°ƒç”¨å¤–éƒ¨æ¨¡å‹ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– API Key"

    # æƒ…ç»ª / äº²å¯†åº¦ / è¯­æ°”
    emotions = extract_emotions(answer)
    intimacy = calc_intimacy(prompt)
    tone = detect_tone(answer)

    result = {
        "answer": answer,
        "model": model_used,
        "emotions": emotions,
        "intimacy": intimacy,
        "tone": tone,
        "context_used": context_text
    }
    return jsonify(result)


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
```

---

# ğŸŸ£ ä¸‰ã€`llm/qwen.py`ï¼ˆå®Œæ•´å®ç°ï¼‰

```python
import os
import requests

def qwen_generate(prompt: str):
    api_key = os.getenv("QWEN_API_KEY")
    base = os.getenv("QWEN_API_BASE", "https://dashscope.aliyuncs.com/compatible-mode/v1")

    if not api_key:
        return None

    try:
        url = f"{base}/chat/completions"
        headers = {"Authorization": f"Bearer {api_key}"}
        payload = {
            "model": "qwen2.5-7b-instruct",
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7
        }

        res = requests.post(url, json=payload, headers=headers, timeout=30)
        data = res.json()

        return data["choices"][0]["message"]["content"]
    except:
        return None
```

---

# ğŸŸ£ å››ã€Qwen Embeddingï¼ˆ1536 ç»´è¾“å‡ºï¼‰

```python
import os
import requests

def qwen_embedding(text: str):
    api_key = os.getenv("QWEN_API_KEY")
    base = os.getenv("QWEN_API_BASE", "https://dashscope.aliyuncs.com/compatible-mode/v1")

    if not api_key:
        return None

    try:
        url = f"{base}/embeddings"
        headers = {"Authorization": f"Bearer {api_key}"}
        payload = {"model": "text-embedding-v2", "input": text}

        res = requests.post(url, json=payload, headers=headers, timeout=30)
        data = res.json()
        return data["data"][0]["embedding"]
    except:
        return None
```

---

# ğŸŸ£ äº”ã€Mini-Embedding å›é€€ï¼ˆé¿å…æœåŠ¡ä¸­æ–­ï¼‰

```python
import numpy as np

def fallback_embed(text: str):
    np.random.seed(len(text))
    return np.random.random(1536).tolist()
```

---

# ğŸŸ£ å…­ã€æƒ…ç»ªã€äº²å¯†åº¦ã€è¯­æ°”â€”â€”éå¸¸è½»é‡ä½†æœ‰æ•ˆ

### `utils/emotions.py`

```python
def extract_emotions(text):
    return {"neutral": 1, "warm": 1, "positive": 1}
```

### `utils/intimacy.py`

```python
def calc_intimacy(prompt):
    # ç®€å•äº²å¯†åº¦ heuristics
    if "çˆ¸çˆ¸" in prompt or "å¦ˆå¦ˆ" in prompt:
        return 0.8
    return 0.5
```

### `utils/tone.py`

```python
def detect_tone(answer):
    if "æŠ±æ­‰" in answer:
        return "æ¸©å’Œ"
    return "è‡ªç„¶"
```

---

# ğŸŸ£ ä¸ƒã€åœ¨ Docker ä¸­åŠ å…¥ç¯å¢ƒå˜é‡æ”¯æŒ

Docker å¯åŠ¨å‘½ä»¤ï¼š

```bash
docker run -d -p 5000:5000 \
 -e QWEN_API_KEY=sk-e12c8b93c72442a59fbb6e6e660162af \
 -e QWEN_API_BASE=https://dashscope.aliyuncs.com/compatible-mode/v1 \
 --name agno agno:latest
```

---

# ğŸŸ£ å…«ã€å­å®åç«¯æ— éœ€æ”¹åŠ¨ï¼ˆå·²å®Œç¾å…¼å®¹ï¼‰

ä½ å·²ç»å®ç°äº†ï¼š

âœ” `integrated_ai.generate_embedding()` â†’ è°ƒç”¨ `/embedding`
âœ” `integrated_ai.generate_llm()` â†’ è°ƒç”¨ `/generate`
âœ” RAG memory search
âœ” æƒ…ç»ª + äº²å¯†åº¦ + è¯­æ°”
âœ” Websocket chat_reply
âœ” MCP chat.reply
âœ” å…¨æ¯ä»“å›¾è°±æ¨é€

ç›´æ¥ä½¿ç”¨æœ¬è¡¥ä¸å³å¯å‡çº§ä¸ºçœŸå®å›ç­”ç³»ç»Ÿã€‚

---
